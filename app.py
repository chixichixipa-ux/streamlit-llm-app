import os
from dotenv import load_dotenv
load_dotenv()

import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
import json
from datetime import datetime

# å°‚é–€å®¶ã®ãƒšãƒ«ã‚½ãƒŠå®šç¾©
EXPERTS = {
    "ğŸ¤– æ±ç”¨AI": {
        "name": "æ±ç”¨AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
        "prompt": "ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã§åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚",
        "description": "ä¸€èˆ¬çš„ãªè³ªå•ã«å¹…åºƒãå¯¾å¿œ"
    },
    "ğŸ’» ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼": {
        "name": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å°‚é–€å®¶",
        "prompt": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªã‚·ãƒ‹ã‚¢ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã§ã™ã€‚ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã€ãƒ‡ãƒãƒƒã‚°ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã«é–¢ã™ã‚‹è³ªå•ã«å¯¾ã—ã¦ã€å®Ÿè·µçš„ã§å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’å«ã‚ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "description": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãƒ»æŠ€è¡“çš„ãªè³ªå•ã«ç‰¹åŒ–"
    },
    "ğŸ“š æ•™å¸«": {
        "name": "æ•™è‚²å°‚é–€å®¶",
        "prompt": "ã‚ãªãŸã¯å„ªç§€ãªæ•™å¸«ã§ã™ã€‚è¤‡é›‘ãªæ¦‚å¿µã‚’åˆ†ã‹ã‚Šã‚„ã™ãã€æ®µéšçš„ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆè©±ã‚„å›³è§£ã‚’ç”¨ã„ã¦ã€åˆå¿ƒè€…ã«ã‚‚ç†è§£ã§ãã‚‹ã‚ˆã†ä¸å¯§ã«æ•™ãˆã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚",
        "description": "å­¦ç¿’ãƒ»æ•™è‚²ã«é–¢ã™ã‚‹è³ªå•ã«æœ€é©"
    },
    "âš•ï¸ åŒ»ç™‚ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼": {
        "name": "åŒ»ç™‚çŸ¥è­˜ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼",
        "prompt": "ã‚ãªãŸã¯åŒ»ç™‚çŸ¥è­˜ã«è©³ã—ã„ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚å¥åº·ã‚„åŒ»ç™‚ã«é–¢ã™ã‚‹ä¸€èˆ¬çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¾ã™ãŒã€å¿…ãšã€Œå°‚é–€åŒ»ã«ç›¸è«‡ã—ã¦ãã ã•ã„ã€ã¨ã„ã†æ³¨æ„æ›¸ãã‚’å«ã‚ã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚",
        "description": "å¥åº·ãƒ»åŒ»ç™‚ã®ä¸€èˆ¬çš„ãªæƒ…å ±æä¾›"
    },
    "ğŸ³ ã‚·ã‚§ãƒ•": {
        "name": "æ–™ç†ã®å°‚é–€å®¶",
        "prompt": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ—ãƒ­ã®ã‚·ã‚§ãƒ•ã§ã™ã€‚æ–™ç†ã®ãƒ¬ã‚·ãƒ”ã€èª¿ç†æŠ€è¡“ã€é£Ÿæã®é¸ã³æ–¹ã«ã¤ã„ã¦ã€å®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚å…·ä½“çš„ãªæ‰‹é †ã¨èª¿ç†ã®ã‚³ãƒ„ã‚’å«ã‚ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "description": "æ–™ç†ãƒ»ãƒ¬ã‚·ãƒ”ã«é–¢ã™ã‚‹è³ªå•ã«ç‰¹åŒ–"
    },
    "ğŸ’¼ ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ": {
        "name": "ãƒ“ã‚¸ãƒã‚¹æˆ¦ç•¥å®¶",
        "prompt": "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚çµŒå–¶æˆ¦ç•¥ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã€æ¥­å‹™æ”¹å–„ã«ã¤ã„ã¦ã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå®Ÿè·µçš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚",
        "description": "ãƒ“ã‚¸ãƒã‚¹ãƒ»çµŒå–¶ã«é–¢ã™ã‚‹ç›¸è«‡ã«å¯¾å¿œ"
    },
    "âœï¸ ãƒ©ã‚¤ã‚¿ãƒ¼": {
        "name": "æ–‡ç« ä½œæˆã®å°‚é–€å®¶",
        "prompt": "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ãƒ©ã‚¤ã‚¿ãƒ¼ãƒ»ç·¨é›†è€…ã§ã™ã€‚é­…åŠ›çš„ã§èª­ã¿ã‚„ã™ã„æ–‡ç« ã®ä½œæˆã€ç·¨é›†ã€æ ¡æ­£ã«ã¤ã„ã¦ã€å…·ä½“çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æ—¥æœ¬èªã§æä¾›ã—ã¦ãã ã•ã„ã€‚æ–‡ç« ã®æ”¹å–„æ¡ˆã‚‚æç¤ºã—ã¦ãã ã•ã„ã€‚",
        "description": "æ–‡ç« ä½œæˆãƒ»ç·¨é›†ã«é–¢ã™ã‚‹è³ªå•ã«ç‰¹åŒ–"
    }
}

# APIã‚­ãƒ¼ã®å–å¾—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã¨Streamlit Cloudä¸¡æ–¹ã«å¯¾å¿œï¼‰
def get_api_key():
    """
    å„ªå…ˆé †ä½:
    1. ç’°å¢ƒå¤‰æ•°ï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«çµŒç”±ï¼‰ - ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨
    2. Streamlit Cloud ã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆ - ãƒ‡ãƒ—ãƒ­ã‚¤ç”¨
    """
    # ã¾ãšç’°å¢ƒå¤‰æ•°ï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‹ã‚‰å–å¾—ã‚’è©¦ã¿ã‚‹
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        return api_key
    
    # ç’°å¢ƒå¤‰æ•°ãŒãªã„å ´åˆã€Streamlit Cloud ã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’ç¢ºèª
    if hasattr(st, "secrets") and "OPENAI_API_KEY" in st.secrets:
        return st.secrets["OPENAI_API_KEY"]
    
    # ã©ã¡ã‚‰ã‚‚ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    st.error("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.info("**ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œã™ã‚‹å ´åˆ:**\n.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€`OPENAI_API_KEY=your-api-key`ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    st.info("**Streamlit Cloudã§å®Ÿè¡Œã™ã‚‹å ´åˆ:**\nã‚¢ãƒ—ãƒªã®è¨­å®šï¼ˆâ‹® â†’ Settings â†’ Secretsï¼‰ã§ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    st.stop()
    return None

st.set_page_config(
    page_title="ğŸ¤– AI ãƒãƒ£ãƒƒãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []
if "total_tokens" not in st.session_state:
    st.session_state.total_tokens = 0
if "selected_expert" not in st.session_state:
    st.session_state.selected_expert = "ğŸ¤– æ±ç”¨AI"
if "chat_history" not in st.session_state:
    st.session_state.chat_history = ChatMessageHistory()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
with st.sidebar:
    st.title("âš™ï¸ è¨­å®š")
    
    # å°‚é–€å®¶é¸æŠ
    st.subheader("ğŸ­ å°‚é–€å®¶ã‚’é¸æŠ")
    selected_expert = st.radio(
        "ç›¸è«‡ã—ãŸã„å°‚é–€å®¶",
        list(EXPERTS.keys()),
        index=list(EXPERTS.keys()).index(st.session_state.selected_expert),
        help="è³ªå•å†…å®¹ã«å¿œã˜ã¦é©åˆ‡ãªå°‚é–€å®¶ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    # å°‚é–€å®¶ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆ
    if selected_expert != st.session_state.selected_expert:
        st.session_state.selected_expert = selected_expert
        st.session_state.messages = []
        st.session_state.chat_history.clear()
        st.rerun()
    
    # é¸æŠã•ã‚ŒãŸå°‚é–€å®¶ã®èª¬æ˜ã‚’è¡¨ç¤º
    st.info(f"**{EXPERTS[selected_expert]['name']}**\n\n{EXPERTS[selected_expert]['description']}")
    
    st.divider()
    
    st.subheader("ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    model = st.selectbox(
        "AIãƒ¢ãƒ‡ãƒ«",
        ["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
        index=0,
        help="ä½¿ç”¨ã™ã‚‹OpenAIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
    )
    
    st.subheader("ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´")
    temperature = st.slider(
        "Temperatureï¼ˆå‰µé€ æ€§ï¼‰",
        min_value=0.0,
        max_value=2.0,
        value=0.7,
        step=0.1,
        help="å€¤ãŒé«˜ã„ã»ã©å‰µé€ çš„ã§äºˆæ¸¬ä¸å¯èƒ½ãªå›ç­”ã«ãªã‚Šã¾ã™"
    )
    
    max_tokens = st.slider(
        "æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°",
        min_value=100,
        max_value=4000,
        value=1000,
        step=100,
        help="ç”Ÿæˆã•ã‚Œã‚‹å›ç­”ã®æœ€å¤§é•·"
    )
    
    st.divider()
    
    # çµ±è¨ˆæƒ…å ±
    st.subheader("ğŸ“Š çµ±è¨ˆæƒ…å ±")
    st.metric("ä¼šè©±ã®ã‚„ã‚Šå–ã‚Šæ•°", len(st.session_state.messages) // 2)
    st.metric("ç´¯è¨ˆãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡", st.session_state.total_tokens)
    
    st.divider()
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ç®¡ç†
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.messages = []
            st.session_state.total_tokens = 0
            st.session_state.chat_history.clear()
            st.rerun()
    
    with col2:
        if st.button("ğŸ’¾ å±¥æ­´ä¿å­˜", use_container_width=True):
            if st.session_state.messages:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"chat_history_{timestamp}.json"
                chat_data = {
                    "timestamp": timestamp,
                    "model": model,
                    "messages": st.session_state.messages
                }
                st.download_button(
                    label="ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=json.dumps(chat_data, ensure_ascii=False, indent=2),
                    file_name=filename,
                    mime="application/json",
                    use_container_width=True
                )

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
current_expert = EXPERTS[st.session_state.selected_expert]
st.title(f"{st.session_state.selected_expert} AI ãƒãƒ£ãƒƒãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.caption(f"ç¾åœ¨ã®å°‚é–€å®¶: {current_expert['name']}")
st.markdown("---")

# LangChain ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
api_key = get_api_key()
if api_key:
    llm = ChatOpenAI(
        api_key=api_key,
        model=model,
        temperature=temperature,
        max_tokens=max_tokens,
        streaming=True
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ä½œæˆ
    prompt = ChatPromptTemplate.from_messages([
        ("system", current_expert['prompt']),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}")
    ])
    
    # ãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ
    chain = prompt | llm
else:
    st.stop()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
chat_container = st.container()
with chat_container:
    for message in st.session_state.messages:
        with st.chat_message(message["role"], avatar="ğŸ§‘â€ğŸ’»" if message["role"] == "user" else "ğŸ¤–"):
            st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt_input := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt_input})
    st.session_state.chat_history.add_user_message(prompt_input)
    
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»"):
        st.markdown(prompt_input)
    
    # AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
    with st.chat_message("assistant", avatar=st.session_state.selected_expert.split()[0]):
        message_placeholder = st.empty()
        full_response = ""
        
        # LangChainã§ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        with st.spinner("è€ƒãˆä¸­..."):
            try:
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ
                for chunk in chain.stream({
                    "input": prompt_input,
                    "history": st.session_state.chat_history.messages
                }):
                    if hasattr(chunk, 'content'):
                        full_response += chunk.content
                        message_placeholder.markdown(full_response + "â–Œ")
                
                message_placeholder.markdown(full_response)
                
                # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
                st.session_state.chat_history.add_ai_message(full_response)
                
                # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®æ›´æ–°ï¼ˆæ¦‚ç®—ï¼‰
                st.session_state.total_tokens += len(prompt_input.split()) + len(full_response.split())
                
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                full_response = "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
        
        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        st.session_state.messages.append({"role": "assistant", "content": full_response})

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown(
    f"""
    <div style='text-align: center; color: gray; font-size: 0.8em;'>
    ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ç•°ãªã‚‹å°‚é–€å®¶ã‚’é¸æŠã—ã¦ã€å°‚é–€çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’å—ã‘ã‚‰ã‚Œã¾ã™
    </div>
    """,
    unsafe_allow_html=True
) 
